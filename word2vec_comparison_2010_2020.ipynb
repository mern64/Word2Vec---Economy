{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word2Vec Comparison: 2010 vs. 2020 Economic Abstracts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_prepare_data(file_path):\n",
        "    \"\"\"Load CSV file and prepare tokenized sentences\"\"\"\n",
        "    df = pd.read_csv(file_path, header=None)\n",
        "    text_data = df[0].astype(str).tolist()\n",
        "    sentences = [sentence.split() for sentence in text_data]\n",
        "    print(f\"Loaded {len(sentences)} documents from {file_path}\")\n",
        "    return sentences\n",
        "\n",
        "# Load both datasets\n",
        "sentences_2010 = load_and_prepare_data(\"2010 -cleaned_abstracts.csv\")\n",
        "sentences_2020 = load_and_prepare_data(\"2020 -cleaned_abstracts.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Word2Vec Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common parameters for both models\n",
        "params = {\n",
        "    'vector_size': 300,\n",
        "    'window': 10,\n",
        "    'min_count': 2,\n",
        "    'workers': 10,\n",
        "    'sg': 1\n",
        "}\n",
        "\n",
        "# Train 2010 model\n",
        "model_2010 = gensim.models.Word2Vec(sentences_2010, **params)\n",
        "model_2010.train(sentences_2010, total_examples=len(sentences_2010), epochs=30)\n",
        "\n",
        "# Train 2020 model\n",
        "model_2020 = gensim.models.Word2Vec(sentences_2020, **params)\n",
        "model_2020.train(sentences_2020, total_examples=len(sentences_2020), epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_word_across_years(word, model1, model2, year1=\"2010\", year2=\"2020\"):\n",
        "    try:\n",
        "        vec1 = model1.wv[word]\n",
        "        vec2 = model2.wv[word]\n",
        "        similarity = model1.wv.cosine_similarities(vec1, [vec2])[0]\n",
        "\n",
        "        print(f\"\\nAnalysis of word: '{word}'\")\n",
        "        print(f\"Cosine similarity between {year1} and {year2}: {similarity:.4f}\")\n",
        "\n",
        "        print(f\"\\nTop 10 neighbors in {year1} model:\")\n",
        "        for neighbor, sim in model1.wv.most_similar(word, topn=10):\n",
        "            print(f\"{neighbor}: {sim:.3f}\")\n",
        "\n",
        "        print(f\"\\nTop 10 neighbors in {year2} model:\")\n",
        "        for neighbor, sim in model2.wv.most_similar(word, topn=10):\n",
        "            print(f\"{neighbor}: {sim:.3f}\")\n",
        "\n",
        "    except KeyError:\n",
        "        print(f\"Word '{word}' not in vocabulary for one or both models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Key Economic Terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "key_terms = [\"market\", \"volatility\", \"liquidity\", \"risk\", \"innovation\"]\n",
        "\n",
        "for term in key_terms:\n",
        "    compare_word_across_years(term, model_2010, model_2020)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_all_similarities(terms, model1, model2):\n",
        "    similarities = {}\n",
        "    for term in terms:\n",
        "        try:\n",
        "            vec1 = model1.wv[term]\n",
        "            vec2 = model2.wv[term]\n",
        "            similarities[term] = model1.wv.cosine_similarities(vec1, [vec2])[0]\n",
        "        except KeyError:\n",
        "            similarities[term] = None\n",
        "\n",
        "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1] if x[1] is not None else -1, reverse=True)\n",
        "\n",
        "    print(\"\\nSummary of Cosine Similarities:\")\n",
        "    for term, sim in sorted_similarities:\n",
        "        if sim is not None:\n",
        "            print(f\"{term}: {sim:.4f}\")\n",
        "        else:\n",
        "            print(f\"{term}: Not in vocabulary\")\n",
        "    return sorted_similarities\n",
        "\n",
        "similarity_results = calculate_all_similarities(key_terms, model_2010, model_2020)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}